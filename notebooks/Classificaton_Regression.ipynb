{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPGWkrQdXU3y6eHtISpgfmt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FranciscoTeon/Video-game-ratings-best-to-worst-Data-Analysis/blob/main/Classificaton_Regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "0-6uUYPU2tcQ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
        "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, mean_squared_error, r2_score, classification_report"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load dataset\n",
        "df = pd.read_csv(\"/content/sample_data/IGN games from best to worst.csv\")\n",
        "\n",
        "# Preprocessing: Convert categorical variables, fill missing data, etc.\n",
        "df = pd.get_dummies(df, drop_first=True)\n",
        "\n",
        "# Handling missing data\n",
        "df.fillna(df.mean(), inplace=True)\n",
        "\n",
        "# Define features (X) and target (y)\n",
        "X = df.drop(columns=['score']) # Features\n",
        "y = df['score']  # Target (could be classification or regression)\n"
      ],
      "metadata": {
        "id": "xxNDjlAy22NP"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "pfl6MRyO27GP"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Experiment 1\n",
        "# Linear Regression (instead of Logistic Regression)\n",
        "\n",
        "# Input (X): Game attributes like genre, developer, year, ratings.\n",
        "# Target (y): Continuous values representing game scores.\n",
        "\n",
        "# Model: Linear Regression\n",
        "lr_model = LinearRegression() # Change to LinearRegression\n",
        "lr_model.fit(X_train, y_train)\n",
        "\n",
        "# Model Performance\n",
        "y_train_pred = lr_model.predict(X_train)\n",
        "y_test_pred = lr_model.predict(X_test)\n",
        "\n",
        "# Use regression metrics (e.g., MSE, R-squared)\n",
        "print(\"Train MSE:\", mean_squared_error(y_train, y_train_pred))\n",
        "print(\"Test MSE:\", mean_squared_error(y_test, y_test_pred))\n",
        "print(\"Train R-squared:\", r2_score(y_train, y_train_pred))\n",
        "print(\"Test R-squared:\", r2_score(y_test, y_test_pred))\n",
        "\n",
        "# Compare train and test metrics\n",
        "\n",
        "lr_model = LinearRegression()  # Change to LinearRegression\n",
        "lr_model.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "-_f2MJLs3OrY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Experiment 1: Linear Regression\n",
        "Input Data and Target:\n",
        "\n",
        "Input (X): Game attributes like genre, developer, year, and ratings (after applying one-hot encoding and filling missing values).\n",
        "Target (y): Continuous values representing game scores.\n",
        "Model Performance:\n",
        "\n",
        "Train MSE: This gives you the mean squared error on the training set.\n",
        "\n",
        "Train MSE: 2.68\n",
        "\n",
        "Test MSE: This is the mean squared error on the test set.\n",
        "\n",
        "Test MSE:\n",
        "1.25\n",
        "×\n",
        "1\n",
        "0\n",
        "22\n",
        "1.25×10\n",
        "22\n",
        "  (very high)\n",
        "\n",
        "Train R-squared: Measures how well the model fits the training data.\n",
        "\n",
        "Train R-squared: 0.09\n",
        "\n",
        "Test R-squared: Shows how well the model generalizes to unseen data.\n",
        "\n",
        "Test R-squared: -\n",
        "4.38\n",
        "×\n",
        "1\n",
        "0\n",
        "21\n",
        "4.38×10\n",
        "21\n",
        "  (extremely poor performance)\n",
        "\n",
        "Overfitting/Underfitting:\n",
        "\n",
        "If the train R-squared is much higher than the test R-squared and test MSE is higher than train MSE, the model may be overfitting.\n",
        "If both the train and test R-squared values are low, the model could be underfitting.\n",
        "Iteration:\n",
        "\n",
        "If overfitting: You can try regularization techniques such as Ridge Regression or Lasso Regression to prevent the model from fitting the noise in the training data.\n",
        "If underfitting: Consider adding more features, or using non-linear models like Polynomial Regression.\n",
        "Potential Improvements:\n",
        "\n",
        "Add more specific features about the games, such as reviews, social media sentiment, or player statistics, to improve model performance.\n",
        "\n",
        "Analysis: The Linear Regression model performed poorly on both the train and test sets, with especially catastrophic results on the test set. The very high MSE and negative R-squared suggest that the model is unable to generalize well. It is likely severely underfitting the data.\n",
        "\n",
        "Next Steps: Linear Regression may not be suitable for this task due to the complexity of the data. Trying more flexible models like Random Forest or Gradient Boosting is a better approach. Regularization (Ridge/Lasso) might also help."
      ],
      "metadata": {
        "id": "Yk7FuVGt94Os"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Experiment 2\n",
        "# Random Forest\n",
        "\n",
        "# Input (X): Game attributes like genre, developer, year, ratings.\n",
        "# Target (y): Continuous values representing game scores (using regression).\n",
        "\n",
        "# Model: Random Forest Regressor (instead of Classifier)\n",
        "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)  # Changed to Regressor\n",
        "rf_model.fit(X_train, y_train)\n",
        "\n",
        "# Model Performance\n",
        "y_train_pred = rf_model.predict(X_train)\n",
        "y_test_pred = rf_model.predict(X_test)\n",
        "\n",
        "# Use regression metrics (e.g., MSE, R-squared)\n",
        "print(\"Train MSE:\", mean_squared_error(y_train, y_train_pred))\n",
        "print(\"Test MSE:\", mean_squared_error(y_test, y_test_pred))\n",
        "print(\"Train R-squared:\", r2_score(y_train, y_train_pred))\n",
        "print(\"Test R-squared:\", r2_score(y_test, y_test_pred))\n",
        "\n",
        "# Consider Overfitting/Underfitting\n",
        "rf_model = RandomForestRegressor(n_estimators=100, max_depth=10, random_state=42) # Changed to Regressor\n",
        "rf_model.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "dORUOoVN3e7S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Experiment 2: Random Forest Regressor\n",
        "Input Data and Target:\n",
        "\n",
        "Input (X): Game attributes like genre, developer, year, and ratings.\n",
        "Target (y): Continuous values representing game scores.\n",
        "Model Performance:\n",
        "\n",
        "Train MSE: Check how well the model fits the training data.\n",
        "\n",
        "Train MSE: 0.46\n",
        "\n",
        "Test MSE: Indicates how well the model generalizes.\n",
        "\n",
        "Test MSE: 2.74\n",
        "\n",
        "Train R-squared: Typically, Random Forest performs well on training data.\n",
        "\n",
        "Train R-squared: 0.84\n",
        "\n",
        "Test R-squared: Evaluate the generalization of the model.\n",
        "\n",
        "Test R-squared: 0.04\n",
        "\n",
        "Overfitting/Underfitting:\n",
        "\n",
        "Random Forests are prone to overfitting, especially with many trees. If train MSE is very low and test MSE is higher, your model may overfit.\n",
        "Iteration:\n",
        "\n",
        "If overfitting: You can reduce the max_depth of the trees or limit the number of features considered at each split to prevent overfitting.\n",
        "In the code, you already addressed overfitting by limiting the max_depth in the second Random Forest model.\n",
        "Potential Improvements:\n",
        "\n",
        "Increase the number of trees (n_estimators) or fine-tune hyperparameters like max_depth, min_samples_split, etc.\n",
        "Try increasing the diversity of the training data or using techniques like cross-validation to get more robust results.\n",
        "\n",
        "Analysis: The Random Forest model fits the training data very well (with a high R-squared), but its performance on the test set is poor, indicating overfitting. The test R-squared of 0.04 suggests that the model barely explains the variance in the test set.\n",
        "\n",
        "Next Steps: To reduce overfitting, limiting tree depth (max_depth) and reducing the number of features considered at each split could help. Cross-validation could also be used to fine-tune hyperparameters.\n"
      ],
      "metadata": {
        "id": "-My1DD8-995d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Experiment 3\n",
        "# Gradient Boosting\n",
        "\n",
        "# Input (X): Game attributes like genre, developer, year, ratings.\n",
        "# Target (y): Continuous values representing game scores (using regression).\n",
        "\n",
        "# Model: Gradient Boosting Regressor (instead of Classifier)\n",
        "gb_model = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, random_state=42) # Changed to Regressor\n",
        "gb_model.fit(X_train, y_train)\n",
        "\n",
        "# Model Performance\n",
        "y_train_pred = gb_model.predict(X_train)\n",
        "y_test_pred = gb_model.predict(X_test)\n",
        "\n",
        "# Use regression metrics (e.g., MSE, R-squared)\n",
        "from sklearn.metrics import mean_squared_error, r2_score # Import necessary metrics\n",
        "print(\"Train MSE:\", mean_squared_error(y_train, y_train_pred))\n",
        "print(\"Test MSE:\", mean_squared_error(y_test, y_test_pred))\n",
        "print(\"Train R-squared:\", r2_score(y_train, y_train_pred))\n",
        "print(\"Test R-squared:\", r2_score(y_test, y_test_pred))\n",
        "\n",
        "# Consider Overfitting/Underfitting\n",
        "\n",
        "gb_model = GradientBoostingRegressor(n_estimators=100, learning_rate=0.01, random_state=42) # Changed to Regressor\n",
        "gb_model.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "J63QYsup3tkz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Experiment 3: Gradient Boosting Regressor\n",
        "Input Data and Target:\n",
        "\n",
        "Input (X): Game attributes like genre, developer, year, and ratings.\n",
        "Target (y): Continuous values representing game scores.\n",
        "Model Performance:\n",
        "\n",
        "Train MSE: Shows the training error.\n",
        "\n",
        "Train MSE: 2.63\n",
        "\n",
        "Test MSE: Indicates generalization performance.\n",
        "\n",
        "Test MSE: 2.60\n",
        "\n",
        "Train R-squared: Likely to be high if the model is learning well.\n",
        "\n",
        "Train R-squared: 0.11\n",
        "\n",
        "Test R-squared: May suffer if the model overfits or underfits.\n",
        "\n",
        "Test R-squared: 0.09\n",
        "\n",
        "Overfitting/Underfitting:\n",
        "\n",
        "In Gradient Boosting, overfitting can occur if the learning rate is too high, or if you use too many trees (n_estimators). In your case, reducing the learning rate (as shown in the second Gradient Boosting model) can help combat overfitting.\n",
        "Iteration:\n",
        "\n",
        "You’ve already made a change by lowering the learning rate. If this didn’t help enough, try early stopping (stopping training once the test error stops decreasing) or regularization techniques like subsampling.\n",
        "Potential Improvements:\n",
        "\n",
        "Add more features or use external data to provide more context about each game.\n",
        "You could also use feature importance to select the most significant features, which might improve performance.\n",
        "\n",
        "Analysis: The Gradient Boosting model performs similarly on both the train and test sets, with relatively low MSE and moderate R-squared values. There doesn't appear to be severe overfitting, but the model's ability to explain the variance in the data is still limited.\n",
        "\n",
        "Next Steps: Gradient Boosting can be further tuned by adjusting the learning rate or increasing the number of estimators. Feature engineering or gathering more data could also improve performance."
      ],
      "metadata": {
        "id": "oqwsbuKh-UCG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Extra Credit\n",
        "\n",
        "# Analysis Structure\n",
        "\n",
        "# For Classification Models\n",
        "\n",
        "print(\"Train Accuracy:\", accuracy_score(y_train, y_train_pred))\n",
        "print(\"Test Accuracy:\", accuracy_score(y_test, y_test_pred))\n",
        "print(\"Precision:\", precision_score(y_test, y_test_pred))\n",
        "print(\"Recall:\", recall_score(y_test, y_test_pred))\n",
        "print(\"F1 Score:\", f1_score(y_test, y_test_pred))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_test_pred))\n",
        "\n",
        "# For Regression Models\n",
        "\n",
        "print(\"Train MSE:\", mean_squared_error(y_train, y_train_pred))\n",
        "print(\"Test MSE:\", mean_squared_error(y_test, y_test_pred))\n",
        "print(\"Train R-Squared:\", r2_score(y_train, y_train_pred))\n",
        "print(\"Test R-Squared:\", r2_score(y_test, y_test_pred))"
      ],
      "metadata": {
        "id": "n0ZJIQP38tCJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
